defaults:
  - _self_
  - dataset: ravdess
  - model: wav2vec
  - train: train
  - metrics: metrics
  - logger: default
  - dirs: default

# 글로벌 설정
settings:
  precision: "32"  # "16" or "32"
  torch_dtype: "float32"

# 실험 설정
experiment:
  name: "ravdess_wav2vec"
  tags: ["audio", "emotion", "ravdess"]
  seed: 42

debug:
  enabled: false
  log_shapes: false
  log_values: false
  model_summary: false

project:
  name: "joon_wandb_llm_test"
  timestamp: ${now:%Y%m%d_%H%M%S}
  hydra_cwd: ${hydra:runtime.cwd}
dirs:
  outputs: outputs/${project.timestamp}
  subdirs: ["checkpoints", "logs", "metrics", "reports"]
logger:
  wandb:
    enabled: true
    project_name: ${project.name}
    entity: "ailab_upstage_fastcampus"
    tags: ["tag1"]

logging:
  project_name: "multimodal-emotion"
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  show_separator: false  # 구분선 출력 여부
  show_timestamp: false  # 타임스탬프 출력 여부
  show_model_summary: false  # 모델 구조 출력 여부


model_manager:
  base_path: "models"
  models:
    emotion_llama:
      model_id: "ZebangCheng/Emotion-LLaMA"
      model_type: "causal_lm"
      config:
        torch_dtype: "float16"
        device_map: "auto"
    llava_next:
      model_id: "llava-hf/LLaVA-NeXT-Video-7B-32K-hf"
      model_type: "processor"
      config:
        torch_dtype: "float16"
        device_map: "auto"
    wav2vec:
      model_id: "facebook/wav2vec2-base"
      model_type: "processor"
      config:
        torch_dtype: "float16"

hydra:
  run:
    dir: ${dirs.outputs}/logs/hydra/${project.timestamp}
  output_subdir: null
  job:
    chdir: false

model:
  wav2vec:
    model_id: "facebook/wav2vec2-base"
    model_type: "processor"
    config:
      torch_dtype: "float16"
      output_hidden_states: false
      output_attentions: false
      return_dict: false

